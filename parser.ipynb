{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml import etree, html as lhtml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import attrgetter, itemgetter\n",
    "import time\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_price(dct):\n",
    "    dct1 = dct.copy()\n",
    "    if 'name' in dct1.keys():\n",
    "        del dct1['name']\n",
    "    dct1['ts'] = dct1['x']\n",
    "    dct1['price'] = dct1['y']\n",
    "    del dct1['x']\n",
    "    del dct1['y']\n",
    "    return dct1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_field(thing, name, dct, el_name):\n",
    "    fields = thing.xpath(name)\n",
    "    if len(fields):\n",
    "        dct[el_name] = fields[0]\n",
    "        \n",
    "def get_page(path, n_attempts=5, t_sleep=1, **kwargs):\n",
    "    for i in range(n_attempts):\n",
    "        ret = requests.get(path, **kwargs)\n",
    "        if ret.status_code==200:\n",
    "            return ret\n",
    "        time.sleep(t_sleep)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_(s):\n",
    "    with lock():\n",
    "        print(s, file=sys.stderr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_price(dct):\n",
    "    dct1 = dct.copy()\n",
    "    if 'name' in dct1.keys():\n",
    "        del dct1['name']\n",
    "    dct1['ts'] = dct1['x']\n",
    "    dct1['price'] = dct1['y']\n",
    "    del dct1['x']\n",
    "    del dct1['y']\n",
    "    return dct1\n",
    "\n",
    "def process_one(info):\n",
    "    path_o, idx = info[0], info[1]\n",
    "    path = 'https://gg.deals' + path_o\n",
    "    ret = get_page(path, n_attempts=5, t_sleep=1)\n",
    "    if ret.status_code!=200:\n",
    "        error_('Error: page {} was not read. Code {}'.format(page, ret.status_code))\n",
    "        return\n",
    "    dct = {}\n",
    "    dct['url'] = path\n",
    "    tree = lhtml.fromstring(ret.text)\n",
    "    soup = BeautifulSoup(ret.text, 'lxml')\n",
    "    get_field(tree, '//a[@class=\"active\"]/span/text()', dct, 'name')\n",
    "    get_field(tree, '//div[@class=\"game-info-image\"]/img/attribute::src', dct, 'image')\n",
    "    lnk = tree.xpath('//a[contains(@class, \"game-link-widget\")]/attribute::href')\n",
    "    if len(lnk):\n",
    "        mu = get_page(lnk[0], n_attempts=5, t_sleep=1)\n",
    "        if mu.status_code!=200:\n",
    "            error_('Error: market_url was not read. Code {}. Game {}'.format(mu.status_code, dct['name']))\n",
    "        dct['market_url'] = mu.url\n",
    "    details = tree.xpath('//div[@id=\"game-info-side\"]')\n",
    "    if len(details):\n",
    "        details = details[0]\n",
    "        get_field(details, '//div[@class=\"game-info-details-section game-info-details-section-release\"]/p/text()', dct, \"release_date\")\n",
    "        get_field(details, '//div[@class=\"game-info-details-section game-info-details-section-developer\"]/p/text()', dct, \"developer\")\n",
    "        get_field(details, '//a[@class=\"score-circle score-metascore\"]/span/span/text()', dct, \"metacritic_score\")\n",
    "        get_field(details, '//a[@class=\"score-circle score-userscore\"]/span/span/text()', dct, \"user_score\")\n",
    "        gens = details.xpath('//div[@id=\"game-info-genres\"]/div/a/text()')\n",
    "        if len(gens):\n",
    "            dct[\"genres\"] = gens\n",
    "        \n",
    "        tags = details.xpath('//div[@id=\"game-info-tags\"]/div/a/text()')\n",
    "        if len(tags):\n",
    "            dct[\"tags\"] = tags\n",
    "            \n",
    "        features = details.xpath('//div[@id=\"game-info-features\"]/div/a/text()')\n",
    "        if len(features):\n",
    "            dct[\"features\"] = features\n",
    "\n",
    "    scores = tree.xpath('//div[@class = \"score-col full\"]')\n",
    "    if len(scores):\n",
    "        scores = scores[0]\n",
    "        get_field(scores, '//span[contains(@class, \"reviews-label\")]/text()', dct, \"review_label\")\n",
    "        rc = scores.xpath('//span[contains(@class, \"semi-transparent\")]/text()')\n",
    "        if len(rc):\n",
    "            dct[\"review_count\"] = int(re.sub('[^0-9]', '',rc[0]))\n",
    "    tmp = tree.xpath('//span[contains(@class, \"reviews-label\")]/attribute::title')\n",
    "    if len(tmp):\n",
    "        tmp = tmp[0]\n",
    "        perc = re.search('%', tmp)#.span()[0]\n",
    "        if perc is not None:\n",
    "            perc = perc.span()[0]\n",
    "            dct[\"review_positive_pctg\"] = int(tmp[:perc])\n",
    "    \n",
    "    tmp = soup.find('section', {'id':'game-dlcs'})\n",
    "    if tmp is not None:\n",
    "        tmp = tmp.find_all('a', {'class':\"game-info-title\"})\n",
    "    if tmp is not None:\n",
    "        dct[\"dlcs\"] = list(map(attrgetter('text'), tmp))\n",
    "    tmp = soup.find('section', {'id':'game-packs'})\n",
    "    if tmp is not None:\n",
    "        tmp = tmp.find_all('a', {'class':\"game-info-title\"})\n",
    "    if tmp is not None:\n",
    "        dct[\"packs\"] = list(map(attrgetter('text'), tmp))\n",
    "    \n",
    "    hist = get_page('https://gg.deals/ru/games/chartHistoricalData/{}/?hideKeyshops=1'.format(idx),\n",
    "                    n_attempts=5, t_sleep=1, headers={'X-Requested-With': 'XMLHttpRequest'})\n",
    "    if hist.status_code!=200:\n",
    "        error_('Error: Prise history of {} was not read. Code {}'.format(dct['name'], hist.status_code))\n",
    "    else:\n",
    "        pr = json.loads(hist.text)\n",
    "        if 'chartData' in pr.keys():\n",
    "            if 'deals' in pr['chartData'].keys():\n",
    "                dct[\"price_history\"] = list(map(process_price, pr['chartData']['deals']))\n",
    "    \n",
    "    syss = soup.find('div', {'class':'game-requirements-tabs'})\n",
    "    if syss is not None:\n",
    "        syss = syss.find_all('a', {'role':\"button\"})\n",
    "    if syss is not None:\n",
    "        dct[\"pc_systems\"] = list(map(attrgetter('text'), syss))\n",
    "    tmp = soup.find('div', {'class':'game-info-actions'}).find_all('span', {'class':'count'})\n",
    "    if len(tmp):\n",
    "        #print(tmp)\n",
    "        digs = []\n",
    "        for i in list(map(attrgetter('text'), tmp)):\n",
    "            if not i in digs:\n",
    "                digs.append(i)\n",
    "        #print(digs[0])\n",
    "        #print(digs[1])\n",
    "        #print(digs[2])\n",
    "        if len(digs)==3:\n",
    "            dct[\"wishlist_count\"], dct[\"alert_count\"], dct[\"owners_count\"] = digs[0], digs[1], digs[2]\n",
    "    return dct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [02:58<00:00,  1.68it/s]\n"
     ]
    }
   ],
   "source": [
    "import gzip\n",
    "import json\n",
    "import codecs\n",
    "\n",
    "from multiprocessing.dummy import Pool, Queue\n",
    "\n",
    "links = []\n",
    "ids = []\n",
    "page = 1\n",
    "while len(links)<300:\n",
    "    ret = get_page(\"https://gg.deals/games/?sort=metascore&type=1\",\n",
    "                   n_attempts=5, t_sleep=1, params={'page': page,})\n",
    "    if ret.status_code!=200:\n",
    "        print('Error: page {} was not read. Code {}'.format(page, ret.status_code), file=sys.stderr)\n",
    "    tree = lhtml.fromstring(ret.text)\n",
    "    links += tree.xpath('//a[contains(@class, \"full-link\")]/attribute::href')\n",
    "    ids += tree.xpath('//div[contains(@class, \"grid-list\")]/div/attribute::data-container-game-id')\n",
    "    page += 1\n",
    "\n",
    "links = links[:300]\n",
    "ids = ids[:300]\n",
    "    \n",
    "info = list(zip(links, ids))\n",
    "    \n",
    "queue = Queue(len(info))   # очередь ссылок на книги\n",
    "for i in info[::-1]:\n",
    "    queue.put(i)\n",
    "\n",
    "def process_page_wrapper(i):\n",
    "    with gzip.open('data/part_{:05d}.jsonl.gz'.format(i), mode='wb') as f_json:\n",
    "        f_json = codecs.getwriter('utf8')(f_json)\n",
    "\n",
    "        while not queue.empty():\n",
    "            record = process_one(queue.get())\n",
    "            record_str = json.dumps(record, ensure_ascii=False)\n",
    "            print(record_str, file=f_json)\n",
    "\n",
    "            # счетчик должен атомарно обновиться\n",
    "            with lock:\n",
    "                pbar.update(1)\n",
    "\n",
    "\n",
    "with Pool(processes=8) as pool, tqdm(total=queue.qsize()) as pbar:\n",
    "    lock = pbar.get_lock()\n",
    "    pool.map(process_page_wrapper, range(pool._processes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
